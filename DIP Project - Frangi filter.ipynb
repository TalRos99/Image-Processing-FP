{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.filters import frangi\n",
    "from scipy.ndimage import minimum_filter\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(*args):\n",
    "    images = len(args)\n",
    "    rows = int(np.ceil(images / 5.0))   \n",
    "    cols = min(5, images)              \n",
    "\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(8 * cols, 8 * rows))\n",
    "\n",
    "    for i, img in enumerate(args):\n",
    "        if rows == 1:  \n",
    "            if cols == 1: \n",
    "                ax.imshow(img, cmap='gray')\n",
    "            else:  \n",
    "                ax[i].imshow(img, cmap='gray')\n",
    "        else: \n",
    "            row = i // 5\n",
    "            col = i % 5\n",
    "            ax[row, col].imshow(img, cmap='gray')\n",
    "\n",
    "    if images < rows * cols:\n",
    "        for i in range(images, rows * cols):\n",
    "            fig.delaxes(ax.flatten()[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_contrast(layer):\n",
    "    if layer.dtype != np.uint8:\n",
    "        layer = cv2.normalize(layer, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    equalized = cv2.equalizeHist(layer)\n",
    "    return equalized\n",
    "\n",
    "def emphasize_boundaries(layer):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    eroded = cv2.erode(layer, kernel, iterations=1)\n",
    "    dilated = cv2.dilate(eroded, kernel, iterations=1)\n",
    "    return dilated\n",
    "\n",
    "def combine_layers(layers):\n",
    "    combined = np.maximum.reduce(layers)\n",
    "    combined = cv2.normalize(combined, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    return combined\n",
    "\n",
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    stacked_layers = cv2.split(image)\n",
    "    tiff_stack = cv2.imreadmulti(image_path)[1]\n",
    "    enhanced_layers = []\n",
    "    for layer in stacked_layers:\n",
    "        enhanced = enhance_contrast(layer)\n",
    "        emphasized = emphasize_boundaries(enhanced)\n",
    "        enhanced_layers.append(emphasized)\n",
    "\n",
    "    bounded_img = tiff_stack[-1] - tiff_stack[1]\n",
    "    bounded_img = cv2.GaussianBlur(bounded_img, (35,35), 10)\n",
    "    bounded_img[bounded_img > 0] = 255\n",
    "\n",
    "    final_output = combine_layers(enhanced_layers)        \n",
    "    final_output[bounded_img == 0] = 0\n",
    "    return final_output\n",
    "\n",
    "def gamma_correction(img, gamma):\n",
    "    return (np.power(img, gamma))*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_hist(img):\n",
    "    hist, bins = np.histogram(img.flatten(), bins=256, range=[0,255])\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "    cdf_m = np.ma.masked_equal(cdf, 0)\n",
    "    cdf_m = (cdf_m - cdf_m.min()) * 255 / (cdf_m.max() - cdf_m.min())\n",
    "    cdf = np.ma.filled(cdf_m, 0).astype('uint8')\n",
    "    \n",
    "    img_out = cdf[img.flatten().astype('uint8')]\n",
    "    img_out = np.reshape(img_out, img.shape)\n",
    "\n",
    "    return img_out\n",
    "\n",
    "def normalize(img):\n",
    "    return (img - np.min(img))/(np.max(img)- np.min(img))*255\n",
    "\n",
    "def convert_gray_to_rgb(image):\n",
    "    image_rgb = np.stack((image,)*3, axis=-1)\n",
    "    return image_rgb\n",
    "\n",
    "def threshold_image(image, threshold=10, max_value=255):\n",
    "    thresholded_image = np.where(image > threshold, max_value, 0).astype('uint8')\n",
    "    return thresholded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell_mask(thresh):\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n",
    "\n",
    "    min_fiber_length = 30\n",
    "    cells_mask = np.zeros_like(thresh)\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        if max(stats[i, cv2.CC_STAT_WIDTH], stats[i, cv2.CC_STAT_HEIGHT]) > min_fiber_length:\n",
    "            cells_mask[labels == i] = 255\n",
    "    return cells_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image1_func():\n",
    "    # Load image and normalize it\n",
    "    image1 = process_image(\"pic1.TIF\") / 255\n",
    "    gamma = 3\n",
    "    correct_image = gamma_correction(image1, gamma)\n",
    "    image1_fibers = cv2.normalize(gamma_correction(image1, 2), None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    normalized_image = cv2.normalize(correct_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "    # Detect Cell borders\n",
    "    blur = cv2.GaussianBlur(normalized_image, (7,)*2, 0)\n",
    "    ret, thresh = cv2.threshold(blur, 80, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,)*2)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel_open)\n",
    "    \n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,)*2)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,)*2)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel_open)\n",
    "\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,)*2)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel_close)\n",
    "    \n",
    "    cells_mask = create_cell_mask(thresh)\n",
    "    \n",
    "    shape = cv2.MORPH_ELLIPSE\n",
    "    kernel_size = (3,)*2\n",
    "    kernel = cv2.getStructuringElement(shape, kernel_size)\n",
    "    cells_mask = cv2.erode(cells_mask, kernel, iterations=2)\n",
    "\n",
    "    kernel_size = (10,)*2\n",
    "    kernel = cv2.getStructuringElement(shape, kernel_size)\n",
    "    cells_mask = cv2.dilate(cells_mask, kernel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect cell borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(normalized_image, (7,)*2, 0)\n",
    "ret, thresh = cv2.threshold(blur, 80, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "show(normalized_image, blur, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show(thresh, normalized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "show(cells_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show(cells_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = image1_fibers.copy()\n",
    "test[cells_mask == 0] = 0\n",
    "test[image1_fibers <= 30]=0\n",
    "show(test, image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_image = equalize_hist(test)\n",
    "filtered_frangi = frangi(equalized_image, np.arange(0.6,3, 0.3), black_ridges=False)\n",
    "filtered_frangi1 = frangi(equalized_image, np.arange(0.5,3, 1.5), beta=0.3, black_ridges=False)\n",
    "filtered_frangi2 = frangi(equalized_image, np.arange(1,5, 0.8), beta=0.3, gamma=0.7, black_ridges=False)\n",
    "\n",
    "show(filtered_frangi, filtered_frangi1, filtered_frangi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_frangi[cells_mask == 0] = 0  \n",
    "filtered_frangi1[cells_mask == 0] = 0 \n",
    "filtered_frangi2[cells_mask == 0] = 0 \n",
    "\n",
    "show(filtered_frangi, filtered_frangi1, filtered_frangi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_frangi = cv2.dilate(filtered_frangi, (10,)*2)\n",
    "ed_frangi = cv2.erode(ed_frangi, (5,)*2)\n",
    "\n",
    "ed_frangi = cv2.dilate(ed_frangi, (9,)*2)\n",
    "ed_frangi = cv2.erode(ed_frangi, (3,)*2)\n",
    "\n",
    "ed_frangi = cv2.erode(ed_frangi, (5,)*2)\n",
    "ed_frangi = cv2.dilate(ed_frangi, (5,)*2)\n",
    "\n",
    "ed_frangi = cv2.erode(ed_frangi, (15,)*2)\n",
    "\n",
    "show(ed_frangi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_image_frangi = cv2.normalize(ed_frangi, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "image = normalized_image_frangi\n",
    "eq_image = cv2.equalizeHist(image)\n",
    "\n",
    "hist,bins = np.histogram(image.flatten(),256,[0,256])\n",
    "eq_hist,eq_bins = np.histogram(eq_image.flatten(),256,[0,256])\n",
    "\n",
    "show(image, eq_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_image2 = equalize_hist(normalized_image)\n",
    "\n",
    "image_color = convert_gray_to_rgb(equalized_image)\n",
    "\n",
    "color_mask = np.zeros_like(image_color)\n",
    "color_mask[eq_image > eq_image.mean()] = [0, 0, 255]\n",
    "highlighted_image1 = cv2.addWeighted(image_color, 1.0, color_mask, 0.5, 0)\n",
    "\n",
    "image_color = convert_gray_to_rgb(equalized_image2)\n",
    "\n",
    "color_mask = np.zeros_like(image_color)\n",
    "color_mask[eq_image > eq_image.mean()] = [0, 0, 255]\n",
    "highlighted_image2 = cv2.addWeighted(image_color, 1.0, color_mask, 0.5, 0)\n",
    "show(highlighted_image1, highlighted_image2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataScienceIntro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
